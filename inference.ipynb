{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import torch \n",
    "import numpy as np\n",
    "from models import unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Github Repositories\\LabML Unet\\spider-seg-e19005\\models\\unet.py:213: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(m.weight)\n",
      "c:\\Github Repositories\\LabML Unet\\spider-seg-e19005\\models\\unet.py:214: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(m.bias, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (conv_final): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (down_convs): ModuleList(\n",
       "    (0): DownConv(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): DownConv(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): DownConv(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (3): DownConv(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (4): DownConv(\n",
       "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (up_convs): ModuleList(\n",
       "    (0): UpConv(\n",
       "      (upconv): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): UpConv(\n",
       "      (upconv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): UpConv(\n",
       "      (upconv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): UpConv(\n",
       "      (upconv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = unet.UNet(in_channels=1,num_classes=19)\n",
    "#setting cpu for laptop inf testing\n",
    "model.load_state_dict(torch.load(\"C:/Users/Konstantinos/Desktop/Spider Inference Models Test/model_20240319_104349_2\", map_location=torch.device('cpu')))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test In MRI from images removed from training sets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 320, 320)\n",
      "max 3096 min -1000\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n",
      "torch.Size([1, 1, 320, 320])\n",
      "(1, 1, 320, 320)\n",
      "(320, 320)\n"
     ]
    }
   ],
   "source": [
    "in_mha = sitk.ReadImage(\"out_inference/132_t1.mha\")\n",
    "\n",
    "in_arr = sitk.GetArrayFromImage(in_mha)\n",
    "\n",
    "if(in_arr.shape[0] > in_arr.shape[1] or  in_arr.shape[0] > in_arr.shape[2]):\n",
    "    in_arr = np.transpose(in_arr, (2, 0, 1))\n",
    "\n",
    "print(in_arr.shape)\n",
    "\n",
    "#image normalisation\n",
    "for idx in range (in_arr.shape[0]):\n",
    "    #print(in_arr[idx, :, :].shape)\n",
    "    idx_slice = in_arr[idx, : , :]\n",
    "    if (idx == 0):\n",
    "        image_max = np.max(idx_slice)\n",
    "        image_min = np.min(idx_slice)\n",
    "    else:\n",
    "        if(np.max(idx_slice) > image_max):\n",
    "            image_max = np.max(idx_slice)\n",
    "        if(np.min(idx_slice) < image_min):\n",
    "            image_min = np.min(idx_slice)\n",
    "\n",
    "print(\"max\", image_max, \"min\", image_min)\n",
    "\n",
    "out_arr = np.empty_like(in_arr)\n",
    "\n",
    "#convert each slice to tensor run inf on each slice and save in new np arr\n",
    "for idx in range(in_arr.shape[0]):\n",
    "    in_slice = in_arr[idx, :, :]\n",
    "    in_tensor = torch.from_numpy(in_slice)\n",
    "    in_tensor = (in_tensor - image_min) / (image_max - image_min)\n",
    "    in_tensor = in_tensor.to(torch.float32)\n",
    "    in_tensor = in_tensor.unsqueeze(0)\n",
    "    in_tensor = in_tensor.unsqueeze(0)\n",
    "    in_tensor.to('cpu')\n",
    "    print(in_tensor.shape)\n",
    "    #TODO figure out how to get the model to output on variable input size \n",
    "    out_tensor = model(in_tensor)\n",
    "    out_tensor = in_tensor * (image_max - image_min) + image_min\n",
    "    \n",
    "    out_tensor_arr = out_tensor.detach().numpy()\n",
    "\n",
    "    print(out_tensor_arr.shape)\n",
    "\n",
    "    out_arr = out_tensor_arr[0, 0, :, :]  # Selecting the last two dimensions\n",
    "    print(out_arr.shape)\n",
    "\n",
    "    out_image = sitk.GetImageFromArray(out_arr)\n",
    "\n",
    "    sitk.WriteImage(out_image, \"C:/Users/Konstantinos/Desktop/sitk inference out/{}.mha\".format(idx))\n",
    "\n",
    "    \n",
    "\n",
    "    #out_arr = out_tensor.numpy()\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the image into slices in loop and run inference model eval "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-medical-tb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
