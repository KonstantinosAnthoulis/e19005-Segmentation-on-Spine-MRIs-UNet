{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFL78HZcbmSP"
      },
      "source": [
        "\n",
        "Connect to Google Drive for datasets (colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcBj2OvobfY3",
        "outputId": "28f8c7e7-eb9b-490c-bd3c-674444fbe332"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1Wa9Ngfw6QC"
      },
      "source": [
        "Install dependencies (colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOCzMWFLw53J",
        "outputId": "1a06cc2b-3e31-4c79-8917-9c8f90e50b52"
      },
      "outputs": [],
      "source": [
        "#!pip install simpleitk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVzzg3MJnhFU"
      },
      "source": [
        "Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QMgkyFD0Hm3",
        "outputId": "50d2df41-f013-4d5e-8c9a-b2d356fb8a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.widgets import Slider, Button, RadioButtons\n",
        "\n",
        "import scipy\n",
        "\n",
        "import SimpleITK as sitk\n",
        "reader = sitk.ImageFileReader()\n",
        "reader.SetImageIO(\"MetaImageIO\")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "import pathlib\n",
        "\n",
        "from natsort import natsorted\n",
        "\n",
        "#Set GPU/Cuda Device to run model on\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "np.random.seed(46)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H48GvrcPnhFh"
      },
      "source": [
        "Dataset Directories <Br>\n",
        "Comment out directory not in use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "35vekrfdnhFi"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n#Colab Google Drive Directories Toy Dataset\\ndummy_train_img_dir = pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_train_images\")\\ndummy_train_label_dir = pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_train_labels\")\\ndummy_test_img_dir = pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_test_images\")\\ndummy_test_label_dir= pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_test_labels\")\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Toy Dataset Directory from Spider | Grand Challenge \n",
        "dummy_train_img_dir = pathlib.Path(r\"spider_toy_dset/dummy_train_images\")\n",
        "dummy_train_label_dir = pathlib.Path(r\"spider_toy_dset/dummy_train_labels\")\n",
        "dummy_test_img_dir = pathlib.Path(r\"spider_toy_dset/dummy_test_images\")\n",
        "dummy_test_label_dir= pathlib.Path(r\"spider_toy_dset/dummy_test_labels\")\n",
        "\n",
        "'''\n",
        "#Colab Google Drive Directories Toy Dataset\n",
        "dummy_train_img_dir = pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_train_images\")\n",
        "dummy_train_label_dir = pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_train_labels\")\n",
        "dummy_test_img_dir = pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_test_images\")\n",
        "dummy_test_label_dir= pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_test_labels\")\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMoYlYbYnhFl"
      },
      "source": [
        "Image class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mR75OjC82JOO"
      },
      "outputs": [],
      "source": [
        "from transforms import mri_transforms\n",
        "\n",
        "class Mri:\n",
        "    def __init__(self, path):\n",
        "        mri_mha = sitk.ReadImage(path, imageIO = \"MetaImageIO\") #explicitly setting ioreader just in case\n",
        "\n",
        "        #resampling\n",
        "        #mri_mha_resampled = mri_transforms.resample_img(mri_mha, out_spacing= [1, 0.3, 0.3])\n",
        "        #TODO separate resample (bilinear, nearestNeighbor) for images and labels\n",
        "\n",
        "        mri_a = np.array(sitk.GetArrayFromImage(mri_mha)) #mri_array\n",
        "\n",
        "        #transpose array to format z x y\n",
        "        if(mri_a.shape[0] > mri_a.shape[1] or mri_a.shape[0] > mri_a.shape[2]): #if z axis isn't first\n",
        "          mri_a = np.transpose(mri_a, (2, 0, 1))\n",
        "      \n",
        "        mri_a_float32 = mri_a.astype(dtype = np.float32)\n",
        "        #TODO: set bounds to [-1000, 2000] https://en.wikipedia.org/wiki/Hounsfield_scale\n",
        "        self.hu_a = mri_a_float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX_8rD_AyhSQ"
      },
      "source": [
        "Check for sorted directory and dimension order <Br>\n",
        "Get max dimension on x y for zero padding "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMiefYLdyRbn",
        "outputId": "9df4b03e-3cff-4f1a-ec74-55a8cc1ee98b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44\n",
            "spider_toy_dset\\dummy_train_labels\n"
          ]
        }
      ],
      "source": [
        "#get lists from directories\n",
        "label_dir_list = os.listdir(dummy_train_label_dir)\n",
        "image_dir_list = os.listdir(dummy_train_img_dir) \n",
        "#sort lists\n",
        "image_dir_list = natsorted(image_dir_list)\n",
        "label_dir_list = natsorted(label_dir_list)\n",
        "#empty lists to hold x and y dimensions of images\n",
        "dim1_list = []\n",
        "dim2_list = []\n",
        "\n",
        "dirlen = len(os.listdir(dummy_train_label_dir))\n",
        "\n",
        "print(dirlen)\n",
        "\n",
        "print(dummy_train_label_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get max dimension of slice in dset for x y padding (creates 912x912 images, too large for training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x max: 899\n",
            "y max: 514\n"
          ]
        }
      ],
      "source": [
        "for idx in range(0, dirlen):\n",
        "  img_path = dummy_train_img_dir.joinpath(image_dir_list[idx])\n",
        "  label_path = dummy_train_label_dir.joinpath(label_dir_list[idx])\n",
        "\n",
        "  image = Mri(img_path)\n",
        "  label = Mri(label_path)\n",
        "  '''\n",
        "  print(idx, \"image: \", image.hu_a.shape)\n",
        "  print(idx, \"label: \", label.hu_a.shape)\n",
        "  '''\n",
        "  dim1_list.append(image.hu_a.shape[1]) #add x value to list\n",
        "  dim2_list.append(image.hu_a.shape[2]) #add y value to list \n",
        "\n",
        "#calculate max \n",
        "x_dim_max = max(dim1_list)\n",
        "y_dim_max = max(dim2_list)\n",
        "\n",
        "print(\"x max:\", max(dim1_list))\n",
        "print(\"y max:\", max(dim2_list))\n",
        "\n",
        "x_dim_max = 912 \n",
        "y_dim_max = 528\n",
        "#912 and 528 was done by calculating the nearest multiple of 16 **above** x and y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find empty slices in labels <br>\n",
        "Create new label and image arrays without the slices w/o mask info <br>\n",
        "Cell works for 1 image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "size of array before trimming 50\n",
            "size of array after trimming what it should be 30\n",
            "True\n",
            "(30, 578, 448)\n"
          ]
        }
      ],
      "source": [
        "from transforms import array_transforms\n",
        "\n",
        "#grab the first image from the dset for testing\n",
        "img_path = dummy_train_img_dir.joinpath(image_dir_list[0]) \n",
        "label_path = dummy_train_label_dir.joinpath(label_dir_list[0])\n",
        "\n",
        "image = Mri(img_path)\n",
        "label = Mri(label_path)\n",
        "\n",
        "\n",
        "test_image_hu, test_label_hu = array_transforms.remove_empty_slices(image.hu_a, label.hu_a)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For slices that aren't empty delete the surrounding 0s to bring resolution down <br>\n",
        "Will work on the test arrays from the cell above <br>\n",
        "Cell works for 1 image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original image res (30, 578, 448)\n",
            "x max 406\n",
            "y max 143\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(406, 143)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array_transforms.crop_zero(test_image_hu, test_label_hu)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "find max dims for cropping "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'array_transforms' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m image \u001b[38;5;241m=\u001b[39m Mri(img_path)\n\u001b[0;32m      9\u001b[0m label \u001b[38;5;241m=\u001b[39m Mri(label_path)\n\u001b[1;32m---> 11\u001b[0m x ,y \u001b[38;5;241m=\u001b[39m array_transforms\u001b[38;5;241m.\u001b[39mcrop_zero(image\u001b[38;5;241m.\u001b[39mhu_a ,label\u001b[38;5;241m.\u001b[39mhu_a)\n\u001b[0;32m     12\u001b[0m x_max\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m     13\u001b[0m y_max\u001b[38;5;241m.\u001b[39mappend(y)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'array_transforms' is not defined"
          ]
        }
      ],
      "source": [
        "x_max = list()\n",
        "y_max  = list()\n",
        "\n",
        "for idx in range(0, dirlen): #for images in directory \n",
        "  img_path = dummy_train_img_dir.joinpath(image_dir_list[idx])\n",
        "  label_path = dummy_train_label_dir.joinpath(label_dir_list[idx])\n",
        "\n",
        "  image = Mri(img_path)\n",
        "  label = Mri(label_path)\n",
        "\n",
        "  x ,y = array_transforms.crop_zero(image.hu_a ,label.hu_a)\n",
        "  x_max.append(x)\n",
        "  y_max.append(y)\n",
        "\n",
        "\n",
        "print(\"x max in dset\", max(x_max))\n",
        "print(\"y max in dset\", max(y_max))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVwddxJgnhFn"
      },
      "source": [
        "Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9X6rHdnnhFo",
        "outputId": "5e9fab66-6c87-4081-eaee-cd059d8a4445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train dataset len 44\n",
            "test dataset len 10\n"
          ]
        }
      ],
      "source": [
        "from transforms import tensor_transforms\n",
        "\n",
        "class SpiderDataset(Dataset):\n",
        "    def __init__(self, labels_dir, img_dir, transform=None, target_transform=None):\n",
        "        self.labels_dir = labels_dir\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.labels_dir))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label_dir_list = os.listdir(self.labels_dir)\n",
        "        image_dir_list = os.listdir(self.img_dir)\n",
        "\n",
        "        image_dir_list = natsorted(image_dir_list)\n",
        "        label_dir_list = natsorted(label_dir_list)\n",
        "\n",
        "        img_path = self.img_dir.joinpath(image_dir_list[idx])\n",
        "        label_path = self.labels_dir.joinpath(label_dir_list[idx])\n",
        "\n",
        "        image = Mri(img_path)\n",
        "        label = Mri(label_path)\n",
        "\n",
        "        #image = self.transform(image)\n",
        "        #label = self.target_transform(label)\n",
        "\n",
        "        #comment out the part not being used whether for 3d or 2d model \n",
        "    \n",
        "        '''\n",
        "        #3d tensor for 3D CNN\n",
        "        image_tensor = torch.from_numpy(image.hu_a)\n",
        "        label_tensor = torch.from_numpy(label.hu_a)\n",
        "        '''\n",
        "\n",
        "        #2d tensor for 2D CNN, get random slice from image \n",
        "        rand_idx = np.random.randint(0, image.hu_a.shape[0])\n",
        "\n",
        "        image_tensor = torch.from_numpy(image.hu_a[rand_idx])\n",
        "        label_tensor = torch.from_numpy(label.hu_a[rand_idx])\n",
        "        \n",
        "        image_tensor = image_tensor.to(torch.float32)\n",
        "        label_tensor = label_tensor.to(torch.float32)\n",
        "        \n",
        "        #pad to max resolution of slice in dset \n",
        "        image_tensor = tensor_transforms.pad_to_resolution(image_tensor, [x_dim_max, y_dim_max])\n",
        "        label_tensor = tensor_transforms.pad_to_resolution(label_tensor, [x_dim_max, y_dim_max])\n",
        "\n",
        "        image_tensor = image_tensor.unsqueeze(0)\n",
        "        label_tensor = label_tensor.unsqueeze(0)\n",
        "\n",
        "        image_tensor = image_tensor.to(device)\n",
        "        label_tensor = label_tensor.to(device)\n",
        "\n",
        "        return image_tensor, label_tensor\n",
        "\n",
        "#toy train test dataset to test network running\n",
        "dummy_train_set = SpiderDataset(dummy_train_label_dir, dummy_train_img_dir)\n",
        "dummy_test_set = SpiderDataset(dummy_test_label_dir, dummy_test_img_dir)\n",
        "\n",
        "print(\"train dataset len\",dummy_train_set.__len__())\n",
        "print(\"test dataset len\",dummy_test_set.__len__())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zsRlBNG-B6Q"
      },
      "source": [
        "Create Unet Instance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CT7aKn7S-F6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "from models import unet \n",
        "\n",
        "input_channels = 1 #Hounsfield scale\n",
        "output_channels = 1 #Vertebra, disc and spinal canal masks SHOULD BE 3 FOR 3 MASKS\n",
        "model = unet.UNet(in_channels = input_channels, out_channels = output_channels)\n",
        "model.to(device)\n",
        "model.to(torch.float32)\n",
        "for param in model.parameters():\n",
        "    print(param.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcuWKZAD9pHD"
      },
      "source": [
        "Hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4lnCiKNW9sJN"
      },
      "outputs": [],
      "source": [
        "epochs = 1 #testing\n",
        "lr = 0.001 #testing\n",
        "batchsize = 2 #testing\n",
        "loss_func = nn.MSELoss()\n",
        "loss_func.to(device)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=lr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWO0s80znhFr"
      },
      "source": [
        "Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UQL_nxpCnhFs"
      },
      "outputs": [],
      "source": [
        "dummy_train_dataloader = DataLoader(dummy_train_set, batch_size = batchsize, shuffle=True)\n",
        "dummy_test_dataloader = DataLoader(dummy_test_set, batch_size = batchsize, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArQ0KlDx4IiP"
      },
      "source": [
        "Dataloader Iterate through Z Axis of tensor (3D tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsnKSM1S4QCa",
        "outputId": "de0bea75-56c2-4ee9-c19d-4fd27643e95a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 912, 528])\n",
            "torch.Size([2, 1, 912, 528])\n",
            "torch.Size([2, 1, 912, 528])\n",
            "torch.Size([2, 1, 912, 528])\n",
            "torch.Size([2, 1, 912, 528])\n"
          ]
        }
      ],
      "source": [
        "for images, masks in dummy_test_dataloader:\n",
        "  for i in images, masks:\n",
        "    print(i.shape)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxAIK14tWJbp"
      },
      "source": [
        "One Epoch <br>\n",
        "https://pytorch.org/tutorials/beginner/introyt/trainingyt.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jxCZ41T_WOBF"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(dummy_train_dataloader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        #print(\"labels\", labels.shape)\n",
        "        #print(inputs.shape)\n",
        "        #print(device)\n",
        "\n",
        "        #inputs = inputs.transpose(-1,0)\n",
        "        #labels = labels.transpose(-1,0)\n",
        "        #inputs = inputs.reshape(inputs.shape(1), inputs.shape(0), inputs.shape(3), inputs.shape(4))\n",
        "        #labels = labels.reshape(labels.shape(1), labels.shape(0), labels.shape(3), labels.shape(4))\n",
        "\n",
        "      \n",
        "        # Zero your gradients for every batch!\n",
        "        optim.zero_grad()\n",
        "\n",
        "        #2d\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        #print(\"outputs\", outputs.shape)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optim.step()\n",
        "\n",
        "        #3d tensor, probably won't use keeping here just in case  \n",
        "        '''\n",
        "        #run everything while indexing through z axis\n",
        "        for axis in images, masks:\n",
        "          for idx in range(0, axis.size(1)):\n",
        "            # Zero your gradients for every batch!\n",
        "            optim.zero_grad()\n",
        "            print(inputs[:, idx, : ,:])\n",
        "            # Make predictions for this batch\n",
        "            outputs = model(inputs[:, idx, : ,:])\n",
        "\n",
        "            # Compute the loss and its gradients\n",
        "            loss = loss_func(outputs[:, idx, : ,:], labels[:, idx, : ,:])\n",
        "            loss.backward()\n",
        "\n",
        "            # Adjust learning weights\n",
        "            optim.step()\n",
        "        '''\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        #if i % 1000 == 999:\n",
        "            #print(\"goes in\")\n",
        "        last_loss = running_loss / 1000 # loss per batch\n",
        "        print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "        tb_x = epoch_index * len(dummy_train_dataloader) + i + 1\n",
        "        tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "        running_loss = 0.\n",
        "        #if ends here\n",
        "\n",
        "    print(\"loss\", loss)\n",
        "    return last_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyaaV1lYYiFc"
      },
      "source": [
        "Train Loop <br>\n",
        "https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7i7TB_oOYhxQ",
        "outputId": "bfdaa28e-8cbc-4f46-be69-0979a6d3ceff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1:\n",
            "  batch 1 loss: 0.19976498413085939\n",
            "  batch 2 loss: 0.21044821166992186\n",
            "  batch 3 loss: 0.43992636108398436\n",
            "  batch 4 loss: 0.43970892333984374\n",
            "  batch 5 loss: 0.01281009006500244\n",
            "  batch 6 loss: 0.21499440002441406\n",
            "  batch 7 loss: 0.04856193923950195\n",
            "  batch 8 loss: 0.03735653686523437\n",
            "  batch 9 loss: 0.231819091796875\n",
            "  batch 10 loss: 0.08252833557128907\n",
            "  batch 11 loss: 0.2508799438476563\n",
            "  batch 12 loss: 0.22275732421875\n",
            "  batch 13 loss: 0.1282725067138672\n",
            "  batch 14 loss: 0.25326881408691404\n",
            "  batch 15 loss: 0.053211025238037106\n",
            "  batch 16 loss: 0.06931427001953125\n",
            "  batch 17 loss: 0.08249246978759765\n",
            "  batch 18 loss: 0.13095401000976561\n",
            "  batch 19 loss: 0.20681495666503907\n",
            "  batch 20 loss: 0.2998067932128906\n",
            "  batch 21 loss: 0.11057411193847656\n",
            "  batch 22 loss: 0.37276473999023435\n",
            "loss tensor(372.7647, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "avg loss in epoch 0.37276473999023435\n",
            "LOSS train 0.37276473999023435 valid 235.98545837402344\n",
            "EPOCH 2:\n",
            "  batch 1 loss: 0.019615800857543945\n",
            "  batch 2 loss: 0.17776690673828124\n",
            "  batch 3 loss: 0.05777289199829101\n",
            "  batch 4 loss: 0.4241106872558594\n",
            "  batch 5 loss: 0.2018722686767578\n",
            "  batch 6 loss: 0.19072238159179689\n",
            "  batch 7 loss: 0.14968527221679687\n",
            "  batch 8 loss: 0.07597522735595703\n",
            "  batch 9 loss: 0.09082981872558593\n",
            "  batch 10 loss: 0.1865591278076172\n",
            "  batch 11 loss: 0.4163247680664062\n",
            "  batch 12 loss: 0.08097785186767578\n",
            "  batch 13 loss: 0.26584793090820313\n",
            "  batch 14 loss: 0.39259048461914064\n",
            "  batch 15 loss: 0.3381397399902344\n",
            "  batch 16 loss: 0.3766058654785156\n",
            "  batch 17 loss: 0.569017578125\n",
            "  batch 18 loss: 0.27903363037109374\n",
            "  batch 19 loss: 0.4948941955566406\n",
            "  batch 20 loss: 0.23445314025878905\n",
            "  batch 21 loss: 0.06417144775390625\n",
            "  batch 22 loss: 0.05548883438110352\n",
            "loss tensor(55.4888, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "avg loss in epoch 0.05548883438110352\n",
            "LOSS train 0.05548883438110352 valid 156.5713653564453\n",
            "EPOCH 3:\n",
            "  batch 1 loss: 0.17865184020996094\n",
            "  batch 2 loss: 0.06807486724853516\n",
            "  batch 3 loss: 0.26947836303710937\n",
            "  batch 4 loss: 0.33406256103515625\n",
            "  batch 5 loss: 0.26614627075195313\n",
            "  batch 6 loss: 0.2511259918212891\n",
            "  batch 7 loss: 0.10078292083740234\n",
            "  batch 8 loss: 0.12361124420166016\n",
            "  batch 9 loss: 0.36880694580078127\n",
            "  batch 10 loss: 0.5988129272460937\n",
            "  batch 11 loss: 0.299118408203125\n",
            "  batch 12 loss: 0.09330419158935546\n",
            "  batch 13 loss: 0.15506565856933593\n",
            "  batch 14 loss: 0.0031153056621551515\n",
            "  batch 15 loss: 0.18245773315429686\n",
            "  batch 16 loss: 0.06440016937255859\n",
            "  batch 17 loss: 0.2194083709716797\n",
            "  batch 18 loss: 0.17952926635742186\n",
            "  batch 19 loss: 0.1442561798095703\n",
            "  batch 20 loss: 0.09128095245361328\n",
            "  batch 21 loss: 0.37615084838867185\n",
            "  batch 22 loss: 0.2951382751464844\n",
            "loss tensor(295.1383, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "avg loss in epoch 0.2951382751464844\n",
            "LOSS train 0.2951382751464844 valid 187.9764862060547\n",
            "EPOCH 4:\n",
            "  batch 1 loss: 0.15601802062988282\n",
            "  batch 2 loss: 0.03183760643005371\n",
            "  batch 3 loss: 0.286117431640625\n",
            "  batch 4 loss: 0.29484539794921877\n",
            "  batch 5 loss: 0.1329979705810547\n",
            "  batch 6 loss: 0.25294918823242185\n",
            "  batch 7 loss: 0.32136334228515623\n",
            "  batch 8 loss: 0.07665234375\n",
            "  batch 9 loss: 0.21101573181152344\n",
            "  batch 10 loss: 0.20993797302246095\n",
            "  batch 11 loss: 0.4343052978515625\n",
            "  batch 12 loss: 0.10675350189208985\n",
            "  batch 13 loss: 0.03251383972167969\n",
            "  batch 14 loss: 0.15055545043945312\n",
            "  batch 15 loss: 0.14334870910644532\n",
            "  batch 16 loss: 0.22585897827148438\n",
            "  batch 17 loss: 0.010517841339111328\n",
            "  batch 18 loss: 0.182028076171875\n",
            "  batch 19 loss: 0.12668521881103514\n",
            "  batch 20 loss: 0.0007460187673568726\n",
            "  batch 21 loss: 0.2021827392578125\n",
            "  batch 22 loss: 0.07873548889160156\n",
            "loss tensor(78.7355, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "avg loss in epoch 0.07873548889160156\n",
            "LOSS train 0.07873548889160156 valid 223.4909210205078\n",
            "EPOCH 5:\n",
            "  batch 1 loss: 0.1662058563232422\n",
            "  batch 2 loss: 0.3938057861328125\n",
            "  batch 3 loss: 0.03673516845703125\n",
            "  batch 4 loss: 0.07365132904052735\n",
            "  batch 5 loss: 0.4017892150878906\n",
            "  batch 6 loss: 0.19281985473632812\n",
            "  batch 7 loss: 0.14859600830078126\n",
            "  batch 8 loss: 0.00040665894746780393\n",
            "  batch 9 loss: 0.3981806640625\n",
            "  batch 10 loss: 0.07379123687744141\n",
            "  batch 11 loss: 0.08479073333740235\n",
            "  batch 12 loss: 0.1518097686767578\n",
            "  batch 13 loss: 0.0004858741760253906\n",
            "  batch 14 loss: 0.13886158752441408\n",
            "  batch 15 loss: 0.20929429626464843\n",
            "  batch 16 loss: 0.28614154052734375\n",
            "  batch 17 loss: 1.1089830322265626\n",
            "  batch 18 loss: 0.07222774505615234\n",
            "  batch 19 loss: 0.39446722412109375\n",
            "  batch 20 loss: 0.2203614501953125\n",
            "  batch 21 loss: 0.17790489196777343\n",
            "  batch 22 loss: 0.20995506286621093\n",
            "loss tensor(209.9551, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "avg loss in epoch 0.20995506286621093\n",
            "LOSS train 0.20995506286621093 valid 257.66314697265625\n",
            "EPOCH 6:\n",
            "  batch 1 loss: 0.4377046203613281\n",
            "  batch 2 loss: 0.12900578308105468\n",
            "  batch 3 loss: 47.1929921875\n",
            "  batch 4 loss: 0.13137158203125\n",
            "  batch 5 loss: 0.06476095581054687\n",
            "  batch 6 loss: 0.16777389526367187\n",
            "  batch 7 loss: 0.20972850036621093\n",
            "  batch 8 loss: 0.12081196594238282\n",
            "  batch 9 loss: 0.4300940856933594\n",
            "  batch 10 loss: 0.569838134765625\n",
            "  batch 11 loss: 0.13538139343261718\n",
            "  batch 12 loss: 0.1122665786743164\n",
            "  batch 13 loss: 0.08043901824951172\n",
            "  batch 14 loss: 0.14085833740234374\n",
            "  batch 15 loss: 0.20352218627929688\n",
            "  batch 16 loss: 0.0867936782836914\n",
            "  batch 17 loss: 0.08936808776855469\n",
            "  batch 18 loss: 0.09439962768554687\n",
            "  batch 19 loss: 0.38870733642578126\n",
            "  batch 20 loss: 0.10442164611816407\n",
            "  batch 21 loss: 0.08199590301513672\n",
            "  batch 22 loss: 0.12558123016357423\n",
            "loss tensor(125.5812, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "avg loss in epoch 0.12558123016357423\n",
            "LOSS train 0.12558123016357423 valid 133.80747985839844\n",
            "EPOCH 7:\n",
            "  batch 1 loss: 0.2930996704101563\n",
            "  batch 2 loss: 0.10403216552734375\n",
            "  batch 3 loss: 0.13818327331542968\n",
            "  batch 4 loss: 0.21770477294921875\n",
            "  batch 5 loss: 4.1445542126893995e-05\n",
            "  batch 6 loss: 0.2121793670654297\n",
            "  batch 7 loss: 0.10993557739257813\n",
            "  batch 8 loss: 0.10505862426757813\n",
            "  batch 9 loss: 0.012932465553283692\n",
            "  batch 10 loss: 0.05628343963623047\n",
            "  batch 11 loss: 0.26455303955078124\n",
            "  batch 12 loss: 0.14623545837402344\n",
            "  batch 13 loss: 0.2556805267333984\n",
            "  batch 14 loss: 0.13668759155273438\n",
            "  batch 15 loss: 0.22305946350097655\n",
            "  batch 16 loss: 0.14059046936035155\n",
            "  batch 17 loss: 0.08790025329589844\n",
            "  batch 18 loss: 0.1536752166748047\n",
            "  batch 19 loss: 0.006305516719818115\n",
            "  batch 20 loss: 0.10491515350341797\n",
            "  batch 21 loss: 0.3118392333984375\n",
            "  batch 22 loss: 0.055163131713867185\n",
            "loss tensor(55.1631, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "avg loss in epoch 0.055163131713867185\n",
            "LOSS train 0.055163131713867185 valid 117.69034576416016\n",
            "EPOCH 8:\n",
            "  batch 1 loss: 0.041985816955566406\n",
            "  batch 2 loss: 0.2714227294921875\n",
            "  batch 3 loss: 0.005011086463928223\n",
            "  batch 4 loss: 0.14457875061035155\n",
            "  batch 5 loss: 0.425971923828125\n",
            "  batch 6 loss: 0.07754885864257813\n",
            "  batch 7 loss: 0.21720710754394532\n",
            "  batch 8 loss: 0.2586715087890625\n",
            "  batch 9 loss: 0.23040951538085938\n",
            "  batch 10 loss: 0.18403547668457032\n",
            "  batch 11 loss: 0.17023606872558594\n",
            "  batch 12 loss: 0.16282406616210937\n",
            "  batch 13 loss: 0.14902043151855468\n",
            "  batch 14 loss: 0.019130842208862305\n",
            "  batch 15 loss: 1.4861460775136947e-05\n",
            "  batch 16 loss: 0.5365424194335937\n",
            "  batch 17 loss: 0.11372288513183594\n",
            "  batch 18 loss: 0.386673583984375\n",
            "  batch 19 loss: 0.10911283111572266\n",
            "  batch 20 loss: 0.05059457778930664\n",
            "  batch 21 loss: 0.08325813293457031\n",
            "  batch 22 loss: 0.1834772033691406\n",
            "loss tensor(183.4772, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "avg loss in epoch 0.1834772033691406\n",
            "LOSS train 0.1834772033691406 valid 193.9462432861328\n",
            "EPOCH 9:\n",
            "  batch 1 loss: 0.1406092529296875\n",
            "  batch 2 loss: 0.32674676513671874\n",
            "  batch 3 loss: 0.4659696960449219\n",
            "  batch 4 loss: 0.23843434143066405\n",
            "  batch 5 loss: 0.03540225219726562\n",
            "  batch 6 loss: 0.13717686462402343\n",
            "  batch 7 loss: 0.02946898651123047\n",
            "  batch 8 loss: 0.15118521118164063\n",
            "  batch 9 loss: 0.05599969482421875\n",
            "  batch 10 loss: 0.2560965576171875\n",
            "  batch 11 loss: 0.2725049438476562\n",
            "  batch 12 loss: 0.0791357421875\n",
            "  batch 13 loss: 0.10147319030761719\n",
            "  batch 14 loss: 0.20235829162597657\n",
            "  batch 15 loss: 0.3219473571777344\n",
            "  batch 16 loss: 0.17428466796875\n",
            "  batch 17 loss: 0.46834750366210937\n",
            "  batch 18 loss: 0.4914004516601562\n",
            "  batch 19 loss: 0.4075318908691406\n",
            "  batch 20 loss: 0.06037592315673828\n",
            "  batch 21 loss: 0.023893045425415038\n",
            "  batch 22 loss: 0.2004953155517578\n",
            "loss tensor(200.4953, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "avg loss in epoch 0.2004953155517578\n",
            "LOSS train 0.2004953155517578 valid 121.3301010131836\n",
            "EPOCH 10:\n",
            "  batch 1 loss: 0.19350958251953124\n",
            "  batch 2 loss: 0.02584008979797363\n",
            "  batch 3 loss: 0.25214247131347656\n",
            "  batch 4 loss: 0.08217697906494141\n",
            "  batch 5 loss: 0.02588941192626953\n",
            "  batch 6 loss: 6.613807380199432e-05\n",
            "  batch 7 loss: 0.2661593017578125\n",
            "  batch 8 loss: 0.0012112010717391967\n",
            "  batch 9 loss: 0.15423529052734375\n",
            "  batch 10 loss: 1.477773766964674e-05\n",
            "  batch 11 loss: 0.2526236877441406\n",
            "  batch 12 loss: 0.13528680419921876\n",
            "  batch 13 loss: 0.21523747253417969\n",
            "  batch 14 loss: 0.31981158447265623\n",
            "  batch 15 loss: 0.2617339172363281\n",
            "  batch 16 loss: 0.26316644287109375\n",
            "  batch 17 loss: 0.030973499298095702\n",
            "  batch 18 loss: 0.020025606155395507\n",
            "  batch 19 loss: 0.2650018310546875\n",
            "  batch 20 loss: 0.008778569221496581\n",
            "  batch 21 loss: 0.32313760375976563\n",
            "  batch 22 loss: 0.31925277709960936\n",
            "loss tensor(319.2528, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "avg loss in epoch 0.31925277709960936\n",
            "LOSS train 0.31925277709960936 valid 162.4220428466797\n",
            "EPOCH 11:\n",
            "  batch 1 loss: 0.11797288513183593\n",
            "  batch 2 loss: 0.4145767517089844\n",
            "  batch 3 loss: 0.5964696655273437\n",
            "  batch 4 loss: 0.31498046875\n",
            "  batch 5 loss: 0.0937259750366211\n",
            "  batch 6 loss: 0.24354598999023438\n",
            "  batch 7 loss: 0.22886004638671875\n",
            "  batch 8 loss: 0.20991555786132812\n",
            "  batch 9 loss: 1.0511168278753758e-05\n",
            "  batch 10 loss: 0.16668998718261718\n",
            "  batch 11 loss: 0.3716626281738281\n",
            "  batch 12 loss: 1.981990784406662e-05\n",
            "  batch 13 loss: 0.2735010681152344\n",
            "  batch 14 loss: 0.09285873413085938\n",
            "  batch 15 loss: 0.2137863311767578\n",
            "  batch 16 loss: 0.007215295791625977\n",
            "  batch 17 loss: 0.3793001708984375\n",
            "  batch 18 loss: 0.0482122802734375\n",
            "  batch 19 loss: 0.11362007904052734\n",
            "  batch 20 loss: 0.13738406372070314\n",
            "  batch 21 loss: 0.20134161376953125\n",
            "  batch 22 loss: 0.12042707061767578\n",
            "loss tensor(120.4271, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "avg loss in epoch 0.12042707061767578\n",
            "LOSS train 0.12042707061767578 valid 153.22161865234375\n",
            "EPOCH 12:\n",
            "  batch 1 loss: 0.33204632568359377\n",
            "  batch 2 loss: 0.08592783355712891\n",
            "  batch 3 loss: 0.36234072875976564\n",
            "  batch 4 loss: 0.07655103302001953\n",
            "  batch 5 loss: 0.0816032257080078\n",
            "  batch 6 loss: 0.003082176923751831\n",
            "  batch 7 loss: 0.03150365447998047\n",
            "  batch 8 loss: 0.40986947631835935\n",
            "  batch 9 loss: 0.07502043151855468\n",
            "  batch 10 loss: 0.311304931640625\n",
            "  batch 11 loss: 0.04399350357055664\n",
            "  batch 12 loss: 0.31584033203125\n",
            "  batch 13 loss: 0.059345020294189456\n",
            "  batch 14 loss: 0.11994324493408202\n",
            "  batch 15 loss: 0.1591182861328125\n",
            "  batch 16 loss: 0.08218844604492187\n",
            "  batch 17 loss: 0.0037992467880249023\n",
            "  batch 18 loss: 0.47293154907226564\n",
            "  batch 19 loss: 0.29469589233398436\n",
            "  batch 20 loss: 0.28439999389648435\n",
            "  batch 21 loss: 0.14278086853027344\n",
            "  batch 22 loss: 0.256417236328125\n",
            "loss tensor(256.4172, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "avg loss in epoch 0.256417236328125\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Disable gradient computation and reduce memory consumption.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, vdata \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dummy_test_dataloader):\n\u001b[0;32m     28\u001b[0m         vinputs, vlabels \u001b[38;5;241m=\u001b[39m vdata\n\u001b[0;32m     30\u001b[0m         voutputs \u001b[38;5;241m=\u001b[39m model(vinputs)\n",
            "File \u001b[1;32md:\\Software\\Anaconda\\envs\\pytorch-medical\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32md:\\Software\\Anaconda\\envs\\pytorch-medical\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32md:\\Software\\Anaconda\\envs\\pytorch-medical\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32md:\\Software\\Anaconda\\envs\\pytorch-medical\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Cell \u001b[1;32mIn[6], line 53\u001b[0m, in \u001b[0;36mSpiderDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     50\u001b[0m image_tensor \u001b[38;5;241m=\u001b[39m image_tensor\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     51\u001b[0m label_tensor \u001b[38;5;241m=\u001b[39m label_tensor\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m image_tensor \u001b[38;5;241m=\u001b[39m image_tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     54\u001b[0m label_tensor \u001b[38;5;241m=\u001b[39m label_tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image_tensor, label_tensor\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/spider_seg_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 30\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number, writer)\n",
        "    print(\"avg loss in epoch\", avg_loss)\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    # Set the model to evaluation mode, disabling dropout and using population\n",
        "    # statistics for batch normalization.\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient computation and reduce memory consumption.\n",
        "    with torch.no_grad():\n",
        "        for i, vdata in enumerate(dummy_test_dataloader):\n",
        "            vinputs, vlabels = vdata\n",
        "\n",
        "            voutputs = model(vinputs)\n",
        "            vloss = loss_func(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "            \n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    \n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        #commented out saving the model for now to debug loss being 0 \n",
        "        '''\n",
        "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        '''\n",
        "    epoch_number += 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
