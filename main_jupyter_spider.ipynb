{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFL78HZcbmSP"
      },
      "source": [
        "\n",
        "Connect to Google Drive for datasets (colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcBj2OvobfY3",
        "outputId": "28f8c7e7-eb9b-490c-bd3c-674444fbe332"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1Wa9Ngfw6QC"
      },
      "source": [
        "Install dependencies (colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOCzMWFLw53J",
        "outputId": "1a06cc2b-3e31-4c79-8917-9c8f90e50b52"
      },
      "outputs": [],
      "source": [
        "#!pip install simpleitk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVzzg3MJnhFU"
      },
      "source": [
        "Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QMgkyFD0Hm3",
        "outputId": "50d2df41-f013-4d5e-8c9a-b2d356fb8a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.widgets import Slider, Button, RadioButtons\n",
        "\n",
        "import scipy\n",
        "\n",
        "import SimpleITK as sitk\n",
        "reader = sitk.ImageFileReader()\n",
        "reader.SetImageIO(\"MetaImageIO\")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "import pathlib\n",
        "\n",
        "from natsort import natsorted\n",
        "\n",
        "#Set GPU/Cuda Device to run model on\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "np.random.seed(46)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H48GvrcPnhFh"
      },
      "source": [
        "Dataset Directories <Br>\n",
        "Comment out directory not in use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "35vekrfdnhFi"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n#Colab Google Drive Directories Toy Dataset\\ndummy_train_img_dir = pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_train_images\")\\ndummy_train_label_dir = pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_train_labels\")\\ndummy_test_img_dir = pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_test_images\")\\ndummy_test_label_dir= pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_test_labels\")\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Toy Dataset Directory from Spider | Grand Challenge \n",
        "dummy_train_img_dir = pathlib.Path(r\"spider_toy_dset/dummy_train_images\")\n",
        "dummy_train_label_dir = pathlib.Path(r\"spider_toy_dset/dummy_train_labels\")\n",
        "dummy_test_img_dir = pathlib.Path(r\"spider_toy_dset/dummy_test_images\")\n",
        "dummy_test_label_dir= pathlib.Path(r\"spider_toy_dset/dummy_test_labels\")\n",
        "\n",
        "'''\n",
        "#Colab Google Drive Directories Toy Dataset\n",
        "dummy_train_img_dir = pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_train_images\")\n",
        "dummy_train_label_dir = pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_train_labels\")\n",
        "dummy_test_img_dir = pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_test_images\")\n",
        "dummy_test_label_dir= pathlib.Path(r\"/content/gdrive/MyDrive/Spider Dummy Dataset/dummy_test_labels\")\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMoYlYbYnhFl"
      },
      "source": [
        "Image class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mR75OjC82JOO"
      },
      "outputs": [],
      "source": [
        "from transforms import mri_transforms\n",
        "\n",
        "class Mri:\n",
        "    def __init__(self, path):\n",
        "        mri_mha = sitk.ReadImage(path, imageIO = \"MetaImageIO\") #explicitly setting ioreader just in case\n",
        "\n",
        "        #resampling\n",
        "        #mri_mha_resampled = mri_transforms.resample_img(mri_mha, out_spacing= [1, 0.3, 0.3])\n",
        "        #TODO separate resample (bilinear, nearestNeighbor) for images and labels\n",
        "\n",
        "        mri_a = np.array(sitk.GetArrayFromImage(mri_mha)) #mri_array\n",
        "\n",
        "        #transpose array to format z x y\n",
        "        if(mri_a.shape[0] > mri_a.shape[1] or mri_a.shape[0] > mri_a.shape[2]): #if z axis isn't first\n",
        "          mri_a = np.transpose(mri_a, (2, 0, 1))\n",
        "      \n",
        "        mri_a_float32 = mri_a.astype(dtype = np.float32)\n",
        "        #TODO: set bounds to [-1000, 2000] https://en.wikipedia.org/wiki/Hounsfield_scale\n",
        "        self.hu_a = mri_a_float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX_8rD_AyhSQ"
      },
      "source": [
        "Check for sorted directory and dimension order <Br>\n",
        "Get max dimension on x y for zero padding "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMiefYLdyRbn",
        "outputId": "9df4b03e-3cff-4f1a-ec74-55a8cc1ee98b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44\n",
            "spider_toy_dset\\dummy_train_labels\n"
          ]
        }
      ],
      "source": [
        "#get lists from directories\n",
        "label_dir_list = os.listdir(dummy_train_label_dir)\n",
        "image_dir_list = os.listdir(dummy_train_img_dir) \n",
        "#sort lists\n",
        "image_dir_list = natsorted(image_dir_list)\n",
        "label_dir_list = natsorted(label_dir_list)\n",
        "#empty lists to hold x and y dimensions of images\n",
        "dim1_list = []\n",
        "dim2_list = []\n",
        "\n",
        "dirlen = len(os.listdir(dummy_train_label_dir))\n",
        "\n",
        "print(dirlen)\n",
        "\n",
        "print(dummy_train_label_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get max dimension of slice in dset for x y padding (creates 912x912 images, too large for training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x max: 899\n",
            "y max: 514\n"
          ]
        }
      ],
      "source": [
        "for idx in range(0, dirlen):\n",
        "  img_path = dummy_train_img_dir.joinpath(image_dir_list[idx])\n",
        "  label_path = dummy_train_label_dir.joinpath(label_dir_list[idx])\n",
        "\n",
        "  image = Mri(img_path)\n",
        "  label = Mri(label_path)\n",
        "  '''\n",
        "  print(idx, \"image: \", image.hu_a.shape)\n",
        "  print(idx, \"label: \", label.hu_a.shape)\n",
        "  '''\n",
        "  dim1_list.append(image.hu_a.shape[1]) #add x value to list\n",
        "  dim2_list.append(image.hu_a.shape[2]) #add y value to list \n",
        "\n",
        "#calculate max \n",
        "x_dim_max = max(dim1_list)\n",
        "y_dim_max = max(dim2_list)\n",
        "\n",
        "print(\"x max:\", max(dim1_list))\n",
        "print(\"y max:\", max(dim2_list))\n",
        "\n",
        "x_dim_max = 912 \n",
        "y_dim_max = 528\n",
        "#912 and 528 was done by calculating the nearest multiple of 16 **above** x and y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find empty slices in labels <br>\n",
        "Create new label and image arrays without the slices w/o mask info <br>\n",
        "Cell works for 1 image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "size of array before trimming 50\n",
            "size of array after trimming what it should be 30\n",
            "True\n",
            "(30, 578, 448)\n"
          ]
        }
      ],
      "source": [
        "from transforms import array_transforms\n",
        "\n",
        "#grab the first image from the dset for testing\n",
        "img_path = dummy_train_img_dir.joinpath(image_dir_list[0]) \n",
        "label_path = dummy_train_label_dir.joinpath(label_dir_list[0])\n",
        "\n",
        "image = Mri(img_path)\n",
        "label = Mri(label_path)\n",
        "\n",
        "\n",
        "test_image_hu, test_label_hu = array_transforms.remove_empty_slices(image.hu_a, label.hu_a)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For slices that aren't empty delete the surrounding 0s to bring resolution down <br>\n",
        "Will work on the test arrays from the cell above <br>\n",
        "Cell works for 1 image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original image res (30, 578, 448)\n",
            "x max 406\n",
            "y max 143\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(406, 143)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array_transforms.crop_zero(test_image_hu, test_label_hu)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "find max dims for cropping "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'array_transforms' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m image \u001b[38;5;241m=\u001b[39m Mri(img_path)\n\u001b[0;32m      9\u001b[0m label \u001b[38;5;241m=\u001b[39m Mri(label_path)\n\u001b[1;32m---> 11\u001b[0m x ,y \u001b[38;5;241m=\u001b[39m array_transforms\u001b[38;5;241m.\u001b[39mcrop_zero(image\u001b[38;5;241m.\u001b[39mhu_a ,label\u001b[38;5;241m.\u001b[39mhu_a)\n\u001b[0;32m     12\u001b[0m x_max\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m     13\u001b[0m y_max\u001b[38;5;241m.\u001b[39mappend(y)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'array_transforms' is not defined"
          ]
        }
      ],
      "source": [
        "x_max = list()\n",
        "y_max  = list()\n",
        "\n",
        "for idx in range(0, dirlen): #for images in directory \n",
        "  img_path = dummy_train_img_dir.joinpath(image_dir_list[idx])\n",
        "  label_path = dummy_train_label_dir.joinpath(label_dir_list[idx])\n",
        "\n",
        "  image = Mri(img_path)\n",
        "  label = Mri(label_path)\n",
        "\n",
        "  x ,y = array_transforms.crop_zero(image.hu_a ,label.hu_a)\n",
        "  x_max.append(x)\n",
        "  y_max.append(y)\n",
        "\n",
        "\n",
        "print(\"x max in dset\", max(x_max))\n",
        "print(\"y max in dset\", max(y_max))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVwddxJgnhFn"
      },
      "source": [
        "Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9X6rHdnnhFo",
        "outputId": "5e9fab66-6c87-4081-eaee-cd059d8a4445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train dataset len 44\n",
            "test dataset len 10\n"
          ]
        }
      ],
      "source": [
        "from transforms import tensor_transforms\n",
        "\n",
        "class SpiderDataset(Dataset):\n",
        "    def __init__(self, labels_dir, img_dir, transform=None, target_transform=None):\n",
        "        self.labels_dir = labels_dir\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.labels_dir))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label_dir_list = os.listdir(self.labels_dir)\n",
        "        image_dir_list = os.listdir(self.img_dir)\n",
        "\n",
        "        image_dir_list = natsorted(image_dir_list)\n",
        "        label_dir_list = natsorted(label_dir_list)\n",
        "\n",
        "        img_path = self.img_dir.joinpath(image_dir_list[idx])\n",
        "        label_path = self.labels_dir.joinpath(label_dir_list[idx])\n",
        "\n",
        "        image = Mri(img_path)\n",
        "        label = Mri(label_path)\n",
        "\n",
        "        #image = self.transform(image)\n",
        "        #label = self.target_transform(label)\n",
        "\n",
        "        #comment out the part not being used whether for 3d or 2d model \n",
        "    \n",
        "        '''\n",
        "        #3d tensor for 3D CNN\n",
        "        image_tensor = torch.from_numpy(image.hu_a)\n",
        "        label_tensor = torch.from_numpy(label.hu_a)\n",
        "        '''\n",
        "\n",
        "        #2d tensor for 2D CNN, get random slice from image \n",
        "        rand_idx = np.random.randint(0, image.hu_a.shape[0])\n",
        "\n",
        "        image_tensor = torch.from_numpy(image.hu_a[rand_idx])\n",
        "        label_tensor = torch.from_numpy(label.hu_a[rand_idx])\n",
        "        \n",
        "        image_tensor = image_tensor.to(torch.float32)\n",
        "        label_tensor = label_tensor.to(torch.float32)\n",
        "        \n",
        "        #pad to max resolution of slice in dset \n",
        "        image_tensor = tensor_transforms.pad_to_resolution(image_tensor, [x_dim_max, y_dim_max])\n",
        "        label_tensor = tensor_transforms.pad_to_resolution(label_tensor, [x_dim_max, y_dim_max])\n",
        "\n",
        "        image_tensor = image_tensor.unsqueeze(0)\n",
        "        label_tensor = label_tensor.unsqueeze(0)\n",
        "\n",
        "        image_tensor = image_tensor.to(device)\n",
        "        label_tensor = label_tensor.to(device)\n",
        "\n",
        "        return image_tensor, label_tensor\n",
        "\n",
        "#toy train test dataset to test network running\n",
        "dummy_train_set = SpiderDataset(dummy_train_label_dir, dummy_train_img_dir)\n",
        "dummy_test_set = SpiderDataset(dummy_test_label_dir, dummy_test_img_dir)\n",
        "\n",
        "print(\"train dataset len\",dummy_train_set.__len__())\n",
        "print(\"test dataset len\",dummy_test_set.__len__())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zsRlBNG-B6Q"
      },
      "source": [
        "Create Unet Instance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CT7aKn7S-F6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "from models import unet \n",
        "\n",
        "input_channels = 1 #Hounsfield scale\n",
        "output_channels = 1 #Vertebra, disc and spinal canal masks SHOULD BE 3 FOR 3 MASKS\n",
        "model = unet.UNet(in_channels = input_channels, out_channels = output_channels)\n",
        "model.to(device)\n",
        "model.to(torch.float32)\n",
        "for param in model.parameters():\n",
        "    print(param.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcuWKZAD9pHD"
      },
      "source": [
        "Hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4lnCiKNW9sJN"
      },
      "outputs": [],
      "source": [
        "epochs = 1 #testing\n",
        "lr = 0.001 #testing\n",
        "batchsize = 2 #testing\n",
        "loss_func = nn.MSELoss()\n",
        "loss_func.to(device)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=lr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWO0s80znhFr"
      },
      "source": [
        "Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UQL_nxpCnhFs"
      },
      "outputs": [],
      "source": [
        "dummy_train_dataloader = DataLoader(dummy_train_set, batch_size = batchsize, shuffle=True)\n",
        "dummy_test_dataloader = DataLoader(dummy_test_set, batch_size = batchsize, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArQ0KlDx4IiP"
      },
      "source": [
        "Dataloader Iterate through Z Axis of tensor (3D tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsnKSM1S4QCa",
        "outputId": "de0bea75-56c2-4ee9-c19d-4fd27643e95a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 912, 528])\n",
            "torch.Size([2, 1, 912, 528])\n",
            "torch.Size([2, 1, 912, 528])\n",
            "torch.Size([2, 1, 912, 528])\n",
            "torch.Size([2, 1, 912, 528])\n"
          ]
        }
      ],
      "source": [
        "for images, masks in dummy_test_dataloader:\n",
        "  for i in images, masks:\n",
        "    print(i.shape)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxAIK14tWJbp"
      },
      "source": [
        "One Epoch <br>\n",
        "https://pytorch.org/tutorials/beginner/introyt/trainingyt.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jxCZ41T_WOBF"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(dummy_train_dataloader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        print(inputs.shape)\n",
        "        print(device)\n",
        "\n",
        "        #inputs = inputs.transpose(-1,0)\n",
        "        #labels = labels.transpose(-1,0)\n",
        "        #inputs = inputs.reshape(inputs.shape(1), inputs.shape(0), inputs.shape(3), inputs.shape(4))\n",
        "        #labels = labels.reshape(labels.shape(1), labels.shape(0), labels.shape(3), labels.shape(4))\n",
        "\n",
        "      \n",
        "        # Zero your gradients for every batch!\n",
        "        optim.zero_grad()\n",
        "\n",
        "        #2d\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optim.step()\n",
        "\n",
        "        #3d tensor, probably won't use keeping here just in case  \n",
        "        '''\n",
        "        #run everything while indexing through z axis\n",
        "        for axis in images, masks:\n",
        "          for idx in range(0, axis.size(1)):\n",
        "            # Zero your gradients for every batch!\n",
        "            optim.zero_grad()\n",
        "            print(inputs[:, idx, : ,:])\n",
        "            # Make predictions for this batch\n",
        "            outputs = model(inputs[:, idx, : ,:])\n",
        "\n",
        "            # Compute the loss and its gradients\n",
        "            loss = loss_func(outputs[:, idx, : ,:], labels[:, idx, : ,:])\n",
        "            loss.backward()\n",
        "\n",
        "            # Adjust learning weights\n",
        "            optim.step()\n",
        "        '''\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(dummy_train_dataloader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyaaV1lYYiFc"
      },
      "source": [
        "Train Loop <br>\n",
        "https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7i7TB_oOYhxQ",
        "outputId": "bfdaa28e-8cbc-4f46-be69-0979a6d3ceff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1:\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "LOSS train 0.0 valid 185.86248779296875\n",
            "EPOCH 2:\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "LOSS train 0.0 valid 182.6651153564453\n",
            "EPOCH 3:\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "LOSS train 0.0 valid 195.63369750976562\n",
            "EPOCH 4:\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "LOSS train 0.0 valid 159.10787963867188\n",
            "EPOCH 5:\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "torch.Size([2, 1, 912, 528])\n",
            "cuda\n",
            "LOSS train 0.0 valid 252.3809814453125\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/spider_seg_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number, writer)\n",
        "\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    # Set the model to evaluation mode, disabling dropout and using population\n",
        "    # statistics for batch normalization.\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient computation and reduce memory consumption.\n",
        "    with torch.no_grad():\n",
        "        for i, vdata in enumerate(dummy_test_dataloader):\n",
        "            vinputs, vlabels = vdata\n",
        "\n",
        "            voutputs = model(vinputs)\n",
        "            vloss = loss_func(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "            \n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
