{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728ead21-acd1-4602-b234-26980aa7c7c7",
   "metadata": {},
   "source": [
    "Add necessary .py scripts to PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db9f058b-1ac5-4a02-b6b6-93cf70f10ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "path_prefix = \"/home/kanthoulis/spider/\"\n",
    "\n",
    "transforms_dir = path_prefix + \"transforms\"\n",
    "image_dir = path_prefix + \"image\"\n",
    "\n",
    "sys.path.append(transforms_dir)\n",
    "sys.path.append(image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b954fe06-dae5-4a5b-afb1-1fa34bebab1f",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf4a610-2ff4-4133-b59d-2589eb608e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "reader = sitk.ImageFileReader()\n",
    "reader.SetImageIO(\"MetaImageIO\")\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "from natsort import natsorted\n",
    "import sys\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mri\n",
    "import mri_transforms, array_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d67c9ee-ce54-4189-97a1-953d8fc4440a",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b64016d-0a83-4bf9-9f96-061d9a0801d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = \"/home/kanthoulis/spider/dataset/\"\n",
    "#3D image directories\n",
    "train_img_dir = pathlib.Path(path_prefix  + \"train_images\")\n",
    "train_label_dir = pathlib.Path(path_prefix + \"train_labels\")\n",
    "test_img_dir = pathlib.Path(path_prefix + \"test_images\")\n",
    "test_label_dir = pathlib.Path(path_prefix + \"test_labels\")\n",
    "\n",
    "#Directories to extract the 2D slices from the 3D images\n",
    "train_img_slice_dir = pathlib.Path(path_prefix + \"train_image_slices\")\n",
    "train_label_slice_dir = pathlib.Path(path_prefix + \"train_label_slices\")\n",
    "test_img_slice_dir = pathlib.Path(path_prefix + \"test_image_slices\")\n",
    "test_label_slice_dir= pathlib.Path(path_prefix + \"test_label_slices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea58a6fa-a288-43f7-98e2-888154c07d74",
   "metadata": {},
   "source": [
    "Directory lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c609cd-d4ff-43cc-898c-372d927301a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory lengths OK\n",
      "No of 3D series in train set: 304\n",
      "No of 3D series in test set: 76\n"
     ]
    }
   ],
   "source": [
    "#Get lists of the files in the directories \n",
    "image_train_dir_list = os.listdir(train_img_dir) \n",
    "label_train_dir_list = os.listdir(train_label_dir)\n",
    "image_test_dir_list = os.listdir(test_img_dir) \n",
    "label_test_dir_list = os.listdir(test_label_dir)\n",
    "\n",
    "#Sort the lists using natsort \n",
    "    # for sorting to format: 1_t1.mha, 1_t2.mha, 2_t1.mha ...so on\n",
    "image_train_dir_list = natsorted(image_train_dir_list)\n",
    "label_train_dir_list = natsorted(label_train_dir_list)\n",
    "image_test_dir_list = natsorted(image_test_dir_list)\n",
    "label_test_dir_list = natsorted(label_test_dir_list)\n",
    "\n",
    "#Checking for same length for corresponding image/label lists on train/test\n",
    "image_train_dirlen = len(image_train_dir_list)\n",
    "label_train_dirlen = len(label_train_dir_list)\n",
    "image_test_dirlen = len(image_test_dir_list)\n",
    "label_test_dirlen = len(label_test_dir_list)\n",
    "\n",
    "#sys.exit on length mismatch\n",
    "if(image_train_dirlen != label_train_dirlen):\n",
    "    sys.exit(\"Error: Training directories don't have the same amount of images\")\n",
    "elif(image_test_dirlen != label_test_dirlen):\n",
    "    sys.exit(\"Error: Validation directories don't have the same amount of images\")\n",
    "else:\n",
    "    print(\"Directory lengths OK\")\n",
    "#Continuing after checks assign lengths to vars for iterating through each directory\n",
    "train_dirlen = image_train_dirlen\n",
    "test_dirlen = image_test_dirlen\n",
    "\n",
    "print(\"No of 3D series in train set:\", train_dirlen)\n",
    "print(\"No of 3D series in test set:\", test_dirlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cffec5c5-a9f5-4578-8971-84437c50a192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TRAIN images/labels: 100%|██████████| 304/304 [02:27<00:00,  2.06image/s]\n",
      "Processing TEST images/labels: 100%|██████████| 76/76 [00:33<00:00,  2.28image/s]\n"
     ]
    }
   ],
   "source": [
    "#Extracting slices for TRAINING images/labels\n",
    "for idx in tqdm(range(0, train_dirlen), desc=\"Processing TRAIN images/labels\", unit=\"image\"):\n",
    "    img_path = train_img_dir.joinpath(image_train_dir_list[idx])\n",
    "    label_path = train_label_dir.joinpath(label_train_dir_list[idx]) #first part before joinpath is pathlib.Path, second part is the directory of the file \n",
    "\n",
    "    #Get 3D array after pre-processing\n",
    "    image = mri.Mri(img_path, is_label=False, is_train_set=True)\n",
    "    label = mri.Mri(label_path, is_label=True, is_train_set=True) \n",
    "\n",
    "    #Copy\n",
    "    image_a = image.hu_a\n",
    "    label_a = label.hu_a\n",
    "    \n",
    "    #Remove slices with no corresponding mask in label \n",
    "    image_a, label_a = array_transforms.remove_empty_slices(image_a, label_a)\n",
    "\n",
    "    #Extract slices after processing to corresponding directories \n",
    "    array_transforms.extract_slices(image_a, image_train_dir_list[idx], train_img_slice_dir) \n",
    "    array_transforms.extract_slices(label_a, label_train_dir_list[idx], train_label_slice_dir) \n",
    "\n",
    "#Extracting slices for TEST images/labels\n",
    "for idx in tqdm(range(0, test_dirlen), desc=\"Processing TEST images/labels\", unit=\"image\"):\n",
    "    img_path = test_img_dir.joinpath(image_test_dir_list[idx])\n",
    "    label_path = test_label_dir.joinpath(label_test_dir_list[idx]) #first part before joinpath is pathlib.Path, second part is the directory of the file \n",
    "\n",
    "    #Get 3D array after pre-processing\n",
    "    image = mri.Mri(img_path, is_label=False, is_train_set=True)\n",
    "    label = mri.Mri(label_path, is_label=True, is_train_set=True)  #NOTE going to end up resampling ALL images to common voxel spacing to get more data \n",
    "\n",
    "    #Copy\n",
    "    image_a = image.hu_a\n",
    "    label_a = label.hu_a\n",
    " \n",
    "    #Extract slices after processing to corresponding directories \n",
    "    array_transforms.extract_slices(image_a, image_test_dir_list[idx], test_img_slice_dir) \n",
    "    array_transforms.extract_slices(label_a, label_test_dir_list[idx], test_label_slice_dir) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d754f7-19f5-4028-b70e-ac856b662c42",
   "metadata": {},
   "source": [
    "Delete old directories remove clutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a119f425-8697-4eca-80e6-8475dee83e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted folder: /home/kanthoulis/spider/dataset/train_images\n",
      "Deleted folder: /home/kanthoulis/spider/dataset/train_labels\n",
      "Deleted folder: /home/kanthoulis/spider/dataset/test_images\n",
      "Deleted folder: /home/kanthoulis/spider/dataset/test_labels\n"
     ]
    }
   ],
   "source": [
    "def delete_folder(folder_path):\n",
    "    if folder_path.exists() and folder_path.is_dir():\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Deleted folder: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"Folder not found or already deleted: {folder_path}\")\n",
    "\n",
    "delete_folder(train_img_dir)\n",
    "delete_folder(train_label_dir)\n",
    "delete_folder(test_img_dir)\n",
    "delete_folder(test_label_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-venv",
   "language": "python",
   "name": "jupyter-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
